{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required libraries\n",
    "from pyspark import SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To separate position and value\n",
    "def map_func(x):\n",
    "    temp = x.split(',')\n",
    "    if(temp[0] == 'A'):\n",
    "        for k in range(p):\n",
    "            key_string = str(temp[1]+','+str(k))\n",
    "            value_string = str('A,'+temp[2]+','+temp[3])\n",
    "            yield(key_string,value_string) \n",
    "    else:\n",
    "        for i in range(m):\n",
    "            key_string = str(str(i)+','+temp[2])\n",
    "            value_string = str('B,'+temp[1]+','+temp[3])\n",
    "            yield(key_string,value_string) \n",
    "\n",
    "#To perform the sum of product operation             \n",
    "def map_func2(x):\n",
    "    temp_string = x.split('#')\n",
    "    a = []\n",
    "    b = []\n",
    "    for x in range(n):\n",
    "        a.append(0)\n",
    "        b.append(0)\n",
    "\n",
    "    for string in temp_string:\n",
    "        temp = string.split(',')\n",
    "        print(temp)\n",
    "        if(temp[0]=='A'):\n",
    "            a[int(temp[1])] = int(temp[2])\n",
    "        else:\n",
    "            b[int(temp[1])] = int(temp[2])\n",
    "    ans = 0\n",
    "    for i in range(n):\n",
    "        ans += a[i] * b[i]\n",
    "    return str(ans)            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SparkContext is the main entry point for Spark functionality. A SparkContext represents the connection to a Spark cluster, and can be used to create RDDs, accumulators and broadcast variables on that cluster. Once the context is created, a map transformation is applied on the input file. A map is a transformation operation. It applies to each element of RDD and it returns the result as new RDD. FlatMap allows returning 0, 1 or more elements from map function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A,0,0,1',\n",
       " 'A,0,1,2',\n",
       " 'A,1,0,3',\n",
       " 'A,1,1,4',\n",
       " 'B,0,0,1',\n",
       " 'B,0,1,0',\n",
       " 'B,1,0,0',\n",
       " 'B,1,1,1']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define matrix dimensions where A is mxn and B is nxp\n",
    "m = 2\n",
    "n = 2\n",
    "p = 2\n",
    "\n",
    "sc = SparkContext.getOrCreate();\n",
    "numbers = sc.textFile(\"matrix_1.txt\").flatMap(lambda line:line.split(\"\\n\"))\n",
    "numbers.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the position and the value are separated using map_func (defined above). This function generates the values required for multiplication. The output is passed through flatMap(). The output is of the form ('i,j', 'matrixName,index,value'), where (i,j) represents the position of the value in the matrix (matrixName) and index denotes the row/column value for matching the multiplication so that we can do: a_0 * b_0 + a_1 * b_1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('0,0', 'A,0,1'),\n",
       " ('0,1', 'A,0,1'),\n",
       " ('0,0', 'A,1,2'),\n",
       " ('0,1', 'A,1,2'),\n",
       " ('1,0', 'A,0,3'),\n",
       " ('1,1', 'A,0,3'),\n",
       " ('1,0', 'A,1,4'),\n",
       " ('1,1', 'A,1,4'),\n",
       " ('0,0', 'B,0,1'),\n",
       " ('1,0', 'B,0,1'),\n",
       " ('0,1', 'B,0,0'),\n",
       " ('1,1', 'B,0,0'),\n",
       " ('0,0', 'B,1,0'),\n",
       " ('1,0', 'B,1,0'),\n",
       " ('0,1', 'B,1,1'),\n",
       " ('1,1', 'B,1,1')]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mappings = numbers.flatMap(map_func)\n",
    "mappings.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reduceByKey() will perform the merging locally on each mapper before sending results to a reducer, similarly to a “combiner” in MapReduce. The output will be the multiplications which need to occur and position for each multiplication. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1,1', 'A,0,3#A,1,4#B,0,0#B,1,1'),\n",
       " ('0,0', 'A,0,1#A,1,2#B,0,1#B,1,0'),\n",
       " ('0,1', 'A,0,1#A,1,2#B,0,0#B,1,1'),\n",
       " ('1,0', 'A,0,3#A,1,4#B,0,1#B,1,0')]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced_numbers = mappings.reduceByKey(lambda a,b:a+'#'+b)\n",
    "reduced_numbers.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the first value ('1,1', 'A,0,3#A,1,4#B,0,0#B,1,1'). Here, (1,1) is the position of the output value from the multiplication which is given by 'A,0,3#A,1,4#B,0,0#B,1,1'. A,0,3 should be multiplied with B,0,0 and A,1,4 should be multiplied with B,1,1. Now, apply the operation using map_func2(). This will compute the value and map() will return a new RDD by applying the function to each element of the input RDD (reduced_numbers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1,1', '4'), ('0,0', '1'), ('0,1', '2'), ('1,0', '3')]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix = reduced_numbers.map(lambda x : (x[0],map_func2(x[1])))\n",
    "matrix.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A,0,0,1',\n",
       " 'A,0,1,2',\n",
       " 'A,0,2,-1',\n",
       " 'A,1,0,2',\n",
       " 'A,1,1,0',\n",
       " 'A,1,2,1',\n",
       " 'B,0,0,3',\n",
       " 'B,0,1,1',\n",
       " 'B,1,0,0',\n",
       " 'B,1,1,-1',\n",
       " 'B,2,0,-2',\n",
       " 'B,2,1,3']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Repeat for matrix_2.txt, dimenions of A is 2x3 and B is 3x2\n",
    "m = 2\n",
    "n = 3\n",
    "p = 2\n",
    "\n",
    "sc = SparkContext.getOrCreate();\n",
    "numbers = sc.textFile(\"matrix_2.txt\").flatMap(lambda line:line.split(\"\\n\"))\n",
    "numbers.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('0,0', 'A,0,1'),\n",
       " ('0,1', 'A,0,1'),\n",
       " ('0,0', 'A,1,2'),\n",
       " ('0,1', 'A,1,2'),\n",
       " ('0,0', 'A,2,-1'),\n",
       " ('0,1', 'A,2,-1'),\n",
       " ('1,0', 'A,0,2'),\n",
       " ('1,1', 'A,0,2'),\n",
       " ('1,0', 'A,1,0'),\n",
       " ('1,1', 'A,1,0'),\n",
       " ('1,0', 'A,2,1'),\n",
       " ('1,1', 'A,2,1'),\n",
       " ('0,0', 'B,0,3'),\n",
       " ('1,0', 'B,0,3'),\n",
       " ('0,1', 'B,0,1'),\n",
       " ('1,1', 'B,0,1'),\n",
       " ('0,0', 'B,1,0'),\n",
       " ('1,0', 'B,1,0'),\n",
       " ('0,1', 'B,1,-1'),\n",
       " ('1,1', 'B,1,-1'),\n",
       " ('0,0', 'B,2,-2'),\n",
       " ('1,0', 'B,2,-2'),\n",
       " ('0,1', 'B,2,3'),\n",
       " ('1,1', 'B,2,3')]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mappings = numbers.flatMap(map_func)\n",
    "mappings.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1,1', 'A,0,2#A,1,0#A,2,1#B,0,1#B,1,-1#B,2,3'),\n",
       " ('0,0', 'A,0,1#A,1,2#A,2,-1#B,0,3#B,1,0#B,2,-2'),\n",
       " ('0,1', 'A,0,1#A,1,2#A,2,-1#B,0,1#B,1,-1#B,2,3'),\n",
       " ('1,0', 'A,0,2#A,1,0#A,2,1#B,0,3#B,1,0#B,2,-2')]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced_numbers = mappings.reduceByKey(lambda a,b:a+'#'+b)\n",
    "reduced_numbers.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1,1', '5'), ('0,0', '5'), ('0,1', '-4'), ('1,0', '4')]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix = reduced_numbers.map(lambda x : (x[0],map_func2(x[1])))\n",
    "matrix.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
